<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>ICCV 2019 Open Access Repository</title>
    <link rel="stylesheet" type="text/css" href="../../static/conf.css">
    <script type="text/javascript" src="../../static/jquery.js"></script>
    <meta name="citation_title"
          content="Self-Supervised Learning With Geometric Constraints in Monocular Video: Connecting Flow, Depth, and Camera">
    <meta name="citation_author" content="Chen, Yuhua">
    <meta name="citation_author" content="Schmid, Cordelia">
    <meta name="citation_author" content="Sminchisescu, Cristian">
    <meta name="citation_publication_date" content="2019">
    <meta name="citation_conference_title"
          content="Proceedings of the IEEE/CVF International Conference on Computer Vision">
    <meta name="citation_firstpage" content="7063">
    <meta name="citation_lastpage" content="7072">
    <meta name="citation_pdf_url"
          content="http://openaccess.thecvf.com/content_ICCV_2019/papers/Chen_Self-Supervised_Learning_With_Geometric_Constraints_in_Monocular_Video_Connecting_Flow_ICCV_2019_paper.pdf">
</head>
<body>
<div id="header">
    <div id="header_left">
        <a href="http://iccv2019.thecvf.com"><img src="../../img/iccv2019_logo.png" width="175" border="0"
                                                  alt="ICCV 2019"></a>
        <a href="http://www.cv-foundation.org/"><img src="../../img/cropped-cvf-s.jpg" width="175" height="112"
                                                     border="0" alt="CVF"></a>
    </div>
    <div id="header_right">
        <div id="header_title">
            <a href="http://iccv2019.thecvf.com">ICCV 2019</a> <a href="/" class="a_monochrome">open access</a>
        </div>
        <div id="help">
            These ICCV 2019 papers are the Open Access versions, provided by the <a
                href="http://www.cv-foundation.org/">Computer Vision Foundation.</a><br> Except for the watermark, they
            are identical to the accepted versions; the final published version of the proceedings is available on IEEE
            Xplore.
        </div>
        <div id="disclaimer">
            This material is presented to ensure timely dissemination of scholarly and technical work.
            Copyright and all rights therein are retained by authors or by other copyright holders.
            All persons copying this information are expected to adhere to the terms and constraints invoked by each
            author's copyright.<br><br>
            <form action="../../ICCV2019_search.py" method="post">
                <input type="text" name="query">
                <input type="submit" value="Search">
            </form>
        </div>
    </div>
</div>
<div class="clear">
</div>
<div id="content">
    <dl>
        <dd>
            <div id="papertitle">
                Self-Supervised Learning With Geometric Constraints in Monocular Video: Connecting Flow, Depth, and
                Camera
            </div>
            <div id="authors">
                <br><b><i>Yuhua Chen, Cordelia Schmid, Cristian Sminchisescu</i></b>; Proceedings of the IEEE/CVF
                International Conference on Computer Vision (ICCV), 2019, pp. 7063-7072
            </div>
            <font size="5">
                <br><b>Abstract</b>
            </font>
            <br><br>
            <div id="abstract">
                We present GLNet, a self-supervised framework for learning depth, optical flow, camera pose and
                intrinsic parameters from monocular video -- addressing the difficulty of acquiring realistic
                ground-truth for such tasks. We propose three contributions: 1) we design new loss functions that
                capture multiple geometric constraints (eg. epipolar geometry) as well as adaptive photometric loss that
                supports multiple moving objects, rigid and non-rigid, 2) we extend the model such that it predicts
                camera intrinsics, making it applicable to uncalibrated video, and 3) we propose several online
                refinement strategies that rely on the symmetry of our self-supervised loss in training and testing, in
                particular optimizing model parameters and/or the output of different tasks, leveraging their mutual
                interactions. The idea of jointly optimizing the system output, under all geometric and photometric
                constraints can be viewed as a dense generalization of classical bundle adjustment. We demonstrate the
                effectiveness of our method on KITTI and Cityscapes, where we outperform previous self-supervised
                approaches on multiple tasks. We also show good generalization for transfer learning.
            </div>
            <font size="5">
                <br><b>Related Material</b>
            </font>
            <br><br>
            [<a href="../../content_ICCV_2019/papers/Chen_Self-Supervised_Learning_With_Geometric_Constraints_in_Monocular_Video_Connecting_Flow_ICCV_2019_paper.pdf">pdf</a>]
            <div class="link2">[<a class="fakelink" onclick="$(this).siblings('.bibref').slideToggle()">bibtex</a>]
                <div class="bibref">
                    @InProceedings{Chen_2019_ICCV,<br>
                    author = {Chen, Yuhua and Schmid, Cordelia and Sminchisescu, Cristian},<br>
                    title = {Self-Supervised Learning With Geometric Constraints in Monocular Video: Connecting Flow,
                    Depth, and Camera},<br>
                    booktitle = {Proceedings of the IEEE/CVF International Conference on Computer Vision (ICCV)},<br>
                    month = {October},<br>
                    year = {2019}<br>
                    }
                </div>
            </div>
        </dd>
    </dl>
</div>
</body>
</html>
