<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
<head>
    <meta content="text/html; charset=UTF-8" http-equiv="content-type">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <title>CVPR 2019 Open Access Repository</title>
    <link rel="stylesheet" type="text/css" href="../../static/conf.css">
    <script type="text/javascript" src="../../static/jquery.js"></script>
    <meta name="citation_title" content="Self-Supervised Learning of 3D Human Pose Using Multi-View Geometry">
    <meta name="citation_author" content="Kocabas, Muhammed">
    <meta name="citation_author" content="Karagoz, Salih">
    <meta name="citation_author" content="Akbas, Emre">
    <meta name="citation_publication_date" content="2019">
    <meta name="citation_conference_title"
          content="Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition">
    <meta name="citation_firstpage" content="1077">
    <meta name="citation_lastpage" content="1086">
    <meta name="citation_pdf_url"
          content="http://openaccess.thecvf.com/content_CVPR_2019/papers/Kocabas_Self-Supervised_Learning_of_3D_Human_Pose_Using_Multi-View_Geometry_CVPR_2019_paper.pdf">
</head>
<body>
<div id="header">
    <div id="header_left">
        <a href="http://cvpr2019.thecvf.com"><img src="../../img/cvpr2019_logo.png" width="175" border="0"
                                                  alt="CVPR 2019"></a>
        <a href="http://www.cv-foundation.org/"><img src="../../img/cropped-cvf-s.jpg" width="175" height="112"
                                                     border="0" alt="CVF"></a>
    </div>
    <div id="header_right">
        <div id="header_title">
            <a href="http://cvpr2019.thecvf.com">CVPR 2019</a> <a href="/" class="a_monochrome">open access</a>
        </div>
        <div id="help">
            These CVPR 2019 papers are the Open Access versions, provided by the <a
                href="http://www.cv-foundation.org/">Computer Vision Foundation.</a><br> Except for the watermark, they
            are identical to the accepted versions; the final published version of the proceedings is available on IEEE
            Xplore.
        </div>
        <div id="disclaimer">
            This material is presented to ensure timely dissemination of scholarly and technical work.
            Copyright and all rights therein are retained by authors or by other copyright holders.
            All persons copying this information are expected to adhere to the terms and constraints invoked by each
            author's copyright.<br><br>
            <form action="../../CVPR2019_search.py" method="post">
                <input type="text" name="query">
                <input type="submit" value="Search">
            </form>
        </div>
    </div>
</div>
<div class="clear">
</div>
<div id="content">
    <dl>
        <dd>
            <div id="papertitle">
                Self-Supervised Learning of 3D Human Pose Using Multi-View Geometry
            </div>
            <div id="authors">
                <br><b><i>Muhammed Kocabas, Salih Karagoz, Emre Akbas</i></b>; Proceedings of the IEEE/CVF Conference on
                Computer Vision and Pattern Recognition (CVPR), 2019, pp. 1077-1086
            </div>
            <font size="5">
                <br><b>Abstract</b>
            </font>
            <br><br>
            <div id="abstract">
                Training accurate 3D human pose estimators requires large amount of 3D ground-truth data which is costly
                to collect. Various weakly or self supervised pose estimation methods have been proposed due to lack of
                3D data. Nevertheless, these methods, in addition to 2D ground-truth poses, require either additional
                supervision in various forms (e.g. unpaired 3D ground truth data, a small subset of labels) or the
                camera parameters in multiview settings. To address these problems, we present EpipolarPose, a
                self-supervised learning method for 3D human pose estimation, which does not need any 3D ground-truth
                data or camera extrinsics. During training, EpipolarPose estimates 2D poses from multi-view images, and
                then, utilizes epipolar geometry to obtain a 3D pose and camera geometry which are subsequently used to
                train a 3D pose estimator. We demonstrate the effectiveness of our approach on standard benchmark
                datasets (i.e. Human3.6M and MPI-INF-3DHP) where we set the new state-of-the-art among
                weakly/self-supervised methods. Furthermore, we propose a new performance measure Pose Structure Score
                (PSS) which is a scale invariant, structure aware measure to evaluate the structural plausibility of a
                pose with respect to its ground truth. Code and pretrained models are available at
                https://github.com/mkocabas/EpipolarPose
            </div>
            <font size="5">
                <br><b>Related Material</b>
            </font>
            <br><br>
            [<a href="../../content_CVPR_2019/papers/Kocabas_Self-Supervised_Learning_of_3D_Human_Pose_Using_Multi-View_Geometry_CVPR_2019_paper.pdf">pdf</a>]
            <div class="link2">[<a class="fakelink" onclick="$(this).siblings('.bibref').slideToggle()">bibtex</a>]
                <div class="bibref">
                    @InProceedings{Kocabas_2019_CVPR,<br>
                    author = {Kocabas, Muhammed and Karagoz, Salih and Akbas, Emre},<br>
                    title = {Self-Supervised Learning of 3D Human Pose Using Multi-View Geometry},<br>
                    booktitle = {Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition
                    (CVPR)},<br>
                    month = {June},<br>
                    year = {2019}<br>
                    }
                </div>
            </div>
        </dd>
    </dl>
</div>
</body>
</html>
